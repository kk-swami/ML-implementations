{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afde7afb-2f22-42f5-b49e-8a312cf98dc1",
   "metadata": {},
   "source": [
    "# Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a55ac72-da81-4999-bd79-83eda9010356",
   "metadata": {},
   "source": [
    "## Introduction to Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d4911e-9159-4f2e-9146-a15a4884782e",
   "metadata": {},
   "source": [
    "Boosting algorithms typically work on top of decision trees. The 3 most common boosting algorithmsa are adaptive boosting, gradient boosting and xgboost (a variant of gradient boosting)\n",
    "\n",
    "Boosting is an ensemble model which uses a combination of weak learners (typically decision tree stumps) to build a final model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63798de1-3977-491a-b9b6-6ef8151165f8",
   "metadata": {},
   "source": [
    "### Hold on . How is boosting different from bagging ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676ec793-6054-41c6-ae26-ea2444e1fd74",
   "metadata": {},
   "source": [
    "Boosting and bagging are the two major classes of ensemble methods, which both use many weak learners, typically decision trees, the basic philosophy being that a combination of weak learners is better than a single strong learner\n",
    "\n",
    "Bagging is used when the goal is to reduce the variance/overfitting of the classifier. In Random Forest, a popular bagging method, we take several random subsets of data, and with each subset train a decision tree with again a subset of features selected randomly. This double randomness (data and features) helps reduce overfitting. Note that a single decision tree is typically overfit (a high variance model, allowed to grow to a large depth), and the ensembling averages out this overfitting\n",
    "\n",
    "In Boosting, learners are learned sequentially with early learners fitting simple models to the data, and then errors analyzed. Consecutive trees are fit at every step, taking into account in some way the errors/residuals from the previous step. (For example in step 2, increasing the weight of a misclassified example in step 1 , so that you correct for it)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0235ca-5c65-43bd-bf44-d19bc59ac73e",
   "metadata": {},
   "source": [
    "1) In Bagging, each tree is a high variance model (overfits). Ensembling reduces this variance. In boosting, each tree is typically a high bias model (underfits). Ensembling reduces this bias\n",
    "2) Bagging is a parallel process. Since data is sampled randomly with replacements, N such data samples can be taken parallely and trained, and each model is independent of the others\n",
    "Boosting is a sequential process. The tree at the second step depends on the model at the first step.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36996660-c158-4cf4-bcab-4df62046c870",
   "metadata": {},
   "source": [
    "## Comparison of boosting techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c635bc-9f17-41c4-b8b5-a0a4778cbbac",
   "metadata": {},
   "source": [
    "## Adaboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a8efdc-e8ac-4e31-b3ef-5d606f3a3da3",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "In adaboost, at every iteration, up-weighting observations which have a greater error. In addition,each classifier has different weights assigned to it based on the classifierâ€™s performance (more weight is assigned to the classifier when accuracy is more and vice-verse)\n",
    "\n",
    "Each classifier is typically a simple stump (highly underfit model)\n",
    "\n",
    "Mathematically\n",
    "\n",
    "For any classifier i, \n",
    "\n",
    "![error](boosting_pic_1.PNG \"error rate\")\n",
    "\n",
    "Note that average error ei of classifier i is 1 if none of the model outputs match the GT, and 0 if all model outputs match the GT\n",
    "\n",
    "The importance of a given classifier in final output is given by\n",
    "\n",
    "![importance](boosting_pic_2.PNG \"error rate\")\n",
    "\n",
    "alphai is 0 when the classifier classifies half the points correctly and half incorrectly\n",
    "\n",
    "![alpha_plot](boosting_pic_3.PNG \"plot\")\n",
    "\n",
    "Look above for the plot of alpha with epsilon\n",
    "\n"
   ]
  },
  {
   "attachments": {
    "bbf760b9-e989-491f-b799-9dce00b0fd46.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "5212a235-610b-4960-ba1c-c54c2d285f93",
   "metadata": {},
   "source": [
    "In addition, the weights of every sample point is also changed, incorrect samples are given weights\n",
    "\n",
    "The equation for that is\n",
    "\n",
    "![image.png](attachment:bbf760b9-e989-491f-b799-9dce00b0fd46.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2975dded-8647-4df6-9c80-85cffb837ba3",
   "metadata": {},
   "source": [
    "Note that for point j, if prediction under classifier i Ci(xj) = yj, then the weight is reduced in next iteration\n",
    "\n",
    "Whereas if prediction is incorrect under classifier i, the weight is increased under next iteration\n",
    "\n",
    "Zj is the normalization factor to ensure all weights sum to 1\n",
    "\n",
    "The final prediction of each observation is made by aggregating the weighted average of the prediction made by each classifier. AdaBoost might result in overfitting. Hence, no. of trees should be checked and restricted.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6f74ca-731a-435a-8cfd-52fb6eb84133",
   "metadata": {},
   "source": [
    "### Advantages and disadvantages of adaboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80847c5-4552-4892-8f5e-21b202b58643",
   "metadata": {},
   "source": [
    "Adv\n",
    "\n",
    "1) Lesser number of hyperparameters, easier to tweak\n",
    "2) Less prone to overfitting if stumps are chosen\n",
    "3) Initially built for binary classification but now can be used for text/image classification also\n",
    "\n",
    "Disadv\n",
    "\n",
    "1) Very sensitive to noisy data and outliers\n",
    "2) Slower than Xgboost\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a61bcab-e117-450b-bc67-a3379da5520a",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c42735-9f7b-451f-bfa9-3665d898e67f",
   "metadata": {},
   "source": [
    "1) https://analyticsindiamag.com/a-hands-on-guide-to-hybrid-ensemble-learning-models-with-python-code/\n",
    "2) https://analyticsindiamag.com/primer-ensemble-learning-bagging-boosting/\n",
    "3) https://www.kaggle.com/code/prashant111/bagging-vs-boosting/notebook\n",
    "4) https://analyticsindiamag.com/adaboost-vs-gradient-boosting-a-comparison-of-leading-boosting-algorithms/#:~:text=AdaBoost%20is%20the%20first%20designed,Boosting%20more%20flexible%20than%20AdaBoost.\n",
    "5) https://www.analyticsvidhya.com/blog/2020/10/adaboost-and-gradient-boost-comparitive-study-between-2-popular-ensemble-model-techniques/\n",
    "6) https://blog.paperspace.com/adaboost-optimizer/#:~:text=AdaBoost%20is%20an%20ensemble%20learning,turn%20them%20into%20strong%20ones.\n",
    "7) https://datascience.stackexchange.com/questions/39193/adaboost-vs-gradient-boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e849cba-730a-45ed-90b7-585ae5c6d3e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
